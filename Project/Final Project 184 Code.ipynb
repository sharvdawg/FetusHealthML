{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3bcb6dc",
   "metadata": {},
   "source": [
    "# Imports and Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb4f5dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import src as tools\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e367884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "721cc5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: 2126 datapoints, 22 features\n",
      "Shortened Dataset: 2126 datapoints, 7 features\n",
      "True labels of Dataset: (2126, 1)\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(\"C://Users//sharv//184//final//Final Project//fetal_health.csv\")\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\sharv\\\\184\\\\final\\\\FetusHealthML\\\\Project\\\\fetal_health.csv\")\n",
    "print(\"Original dataset:\",df.shape[0],\"datapoints,\",df.shape[1],\"features\")\n",
    "\n",
    "#As discussed in the project proposal, we will experiment with using only the first 7 features that are actual recordings of\n",
    "#the patients monitoring.\n",
    "short_df = df[['baseline value','accelerations','fetal_movement','uterine_contractions'\n",
    "               ,'light_decelerations','severe_decelerations','prolongued_decelerations']]\n",
    "print(\"Shortened Dataset:\",short_df.shape[0],\"datapoints,\",short_df.shape[1],\"features\")\n",
    "\n",
    "#\n",
    "y_labels = df[['fetal_health']]\n",
    "print(\"True labels of Dataset:\",y_labels.shape)\n",
    "#Thankfully all the values are numerical, no need to reencode them\n",
    "# TODO: MAYBE WANT TO NORMALIZE DATASET? CONSIDER DELETING SEVERE_DECELERATIONS COL SINCE ITS ALMOST ALL 0??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41350b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With the dataset prepared, we must split it into training, validation, and testing sets.\n",
    "#Note: The validation set is really only for the Neural Network model. We will do another split for it seperately\n",
    "x_train, x_test, y_train, y_test = train_test_split(short_df, y_labels, test_size=0.2,stratify=y_labels)\n",
    "print(\"Training Set size:\",x_train.shape)\n",
    "print(\"Training Targt size\", y_train.shape)\n",
    "print(\"Testing Set size:\",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7d1e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c60b592",
   "metadata": {},
   "source": [
    "# KNN(small dataset & cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa4e50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Using the KNNClassifier from the sklearnknn_classifier.fit(X_train, y_train) library, we will experiment with different values of k.\n",
    "KNN_testErrors = [0]*250 #index will represent k value. Testing up to k = 500\n",
    "KNN_crossValidationErrors = [0]*250\n",
    "for k in range(250):\n",
    "    k = k+1 #1-250 not 0-249\n",
    "    if(k%25==0):\n",
    "        print(k/2.5) #Scuffed progress bar\n",
    "    # Cross-validation with 5 fold\n",
    "    nFolds = 5\n",
    "    for iFold in range(nFolds):\n",
    "        Xti, Xvi, Yti, Yvi = tools.crossValidate(x_train, y_train,nFolds, iFold)\n",
    "        knnClassifier = KNeighborsClassifier(n_neighbors=k)\n",
    "        knnClassifier.fit(Xti, Yti)\n",
    "    \n",
    "        cross_validation_pred = knnClassifier.predict(Xvi)\n",
    "        y_test_pred = knnClassifier.predict(x_test)\n",
    "    \n",
    "        cross_validation_accuracy = accuracy_score(Yvi,cross_validation_pred)\n",
    "        test_accuracy = accuracy_score(y_test,y_test_pred)\n",
    "\n",
    "        cross_validation_error = 1-cross_validation_accuracy\n",
    "        test_error = 1-test_accuracy\n",
    "        KNN_crossValidationErrors[k-1] += cross_validation_error\n",
    "        KNN_testErrors[k-1] += test_error\n",
    "    KNN_crossValidationErrors[k-1] = KNN_crossValidationErrors[k-1]/nFolds\n",
    "    KNN_testErrors[k-1] = KNN_testErrors[k-1]/nFolds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5078a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(range(1, len(KNN_crossValidationErrors) + 1), KNN_crossValidationErrors, color='g')\n",
    "plt.semilogx(range(1, len(KNN_testErrors) + 1), KNN_testErrors, color='r')\n",
    "plt.xlabel('k Value')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fde4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lowest error rate is\",min(KNN_testErrors),\"at k =\",KNN_testErrors.index(min(KNN_testErrors))+1)\n",
    "# k = KNN_testErrors.index(min(KNN_testErrors))+1 because it's pulling the error rate from a list (starts at 0)\n",
    "#But k values actually start at k = 1\n",
    "bestk = KNN_testErrors.index(min(KNN_testErrors))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac68fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix for best performing KNN.\n",
    "knnClassifier = KNeighborsClassifier(n_neighbors=bestk)\n",
    "knnClassifier.fit(x_train, y_train)\n",
    "y_test_pred = knnClassifier.predict(x_test)\n",
    "matrix = confusion_matrix(y_test, y_test_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=matrix)\n",
    "disp.plot()\n",
    "print(f1_score(y_test, y_test_pred,average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b650d4e",
   "metadata": {},
   "source": [
    "# KNN(normal dataset & NO cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7c686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will repeat the same process, but with the entire dataset. To save time, I will only test for up to k=100. \n",
    "#In all likelihood, the best k value will reveal itself early on\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(df, y_labels, test_size=0.2,stratify=y_labels)\n",
    "print(\"Training Set size:\",x_train2.shape)\n",
    "print(\"Testing Set size:\",x_test2.shape)\n",
    "\n",
    "KNN_testErrors = [] #index will represent k value. Testing up to k = 100\n",
    "KNN_trainErrors = []\n",
    "for k in range(100):\n",
    "    k = k+1 #1-100, not 0-99\n",
    "    if(k%10==0):\n",
    "        print(k) #Scuffed progress bar\n",
    "    knnClassifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    knnClassifier.fit(x_train2, y_train2.values.ravel())\n",
    "    \n",
    "    y_train_pred2 = knnClassifier.predict(x_train2)\n",
    "    y_test_pred2 = knnClassifier.predict(x_test2)\n",
    "    \n",
    "    train_accuracy2 = accuracy_score(y_train2,y_train_pred2)\n",
    "    test_accuracy2 = accuracy_score(y_test2,y_test_pred2)\n",
    "    train_error2 = 1-train_accuracy2\n",
    "    test_error2 = 1-test_accuracy2\n",
    "    KNN_trainErrors.append(train_error2)\n",
    "    KNN_testErrors.append(test_error2)\n",
    "    \n",
    "plt.semilogx(range(1, len(KNN_trainErrors) + 1), KNN_trainErrors, color='g')\n",
    "plt.semilogx(range(1, len(KNN_testErrors) + 1), KNN_testErrors, color='r')\n",
    "plt.xlabel('k Value')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.show()\n",
    "\n",
    "bestk = KNN_testErrors.index(min(KNN_testErrors))+1\n",
    "print(\"Lowest error rate is\",min(KNN_testErrors),\"at k =\",bestk)\n",
    "\n",
    "knnClassifier = KNeighborsClassifier(n_neighbors=bestk)\n",
    "knnClassifier.fit(x_train2, y_train2.values.ravel())\n",
    "y_test_pred2 = knnClassifier.predict(x_test2)\n",
    "\n",
    "matrix = confusion_matrix(y_test2, y_test_pred2)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=matrix)\n",
    "disp.plot()\n",
    "f1_score(y_test2, y_test_pred2, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31a3874",
   "metadata": {},
   "source": [
    "# KNN(normal dataset & cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83a7aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will repeat the same process, but with the entire dataset. To save time, I will only test for up to k=100. \n",
    "#In all likelihood, the best k value will reveal itself early on\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(df, y_labels, test_size=0.2,stratify=y_labels)\n",
    "print(\"Training Set size:\",x_train2.shape)\n",
    "print(\"Testing Set size:\",x_test2.shape)\n",
    "x_train2 = np.array(x_train2)\n",
    "x_test2 = np.array(x_test2)\n",
    "y_train2 = np.array(y_train2)\n",
    "y_test2 = np.array(y_test2)\n",
    "\n",
    "KNN_testErrors = [0]*100 #index will represent k value. Testing up to k = 100\n",
    "KNN_trainErrors = [0]*100\n",
    "for k in range(100):\n",
    "    k = k+1 #1-100, not 0-99\n",
    "    if(k%10==0):\n",
    "        print(k) #Scuffed progress bar\n",
    "    nFolds = 5\n",
    "    for iFold in range(nFolds):\n",
    "        Xti, Xvi, Yti, Yvi = tools.crossValidate(x_train2, y_train2,nFolds, iFold)\n",
    "        knnClassifier = KNeighborsClassifier(n_neighbors=k)\n",
    "        knnClassifier.fit(Xti, Yti)\n",
    "    \n",
    "        y_train_pred2 = knnClassifier.predict(Xvi)\n",
    "        y_test_pred2 = knnClassifier.predict(x_test2)\n",
    "    \n",
    "        train_accuracy2 = accuracy_score(Yvi,y_train_pred2)\n",
    "        test_accuracy2 = accuracy_score(y_test2,y_test_pred2)\n",
    "        train_error2 = 1-train_accuracy2\n",
    "        test_error2 = 1-test_accuracy2\n",
    "        KNN_trainErrors[k-1] += train_error2\n",
    "        KNN_testErrors[k-1] += test_error2\n",
    "    KNN_trainErrors[k-1] = KNN_trainErrors[k-1]/5\n",
    "    KNN_testErrors[k-1] += KNN_testErrors[k-1]/5\n",
    "    \n",
    "plt.semilogx(range(1, len(KNN_trainErrors) + 1), KNN_trainErrors, color='g')\n",
    "plt.semilogx(range(1, len(KNN_testErrors) + 1), KNN_testErrors, color='r')\n",
    "plt.xlabel('k Value')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.show()\n",
    "\n",
    "bestk = KNN_testErrors.index(min(KNN_testErrors))+1\n",
    "print(\"Lowest error rate is\",min(KNN_testErrors),\"at k =\",bestk)\n",
    "\n",
    "knnClassifier = KNeighborsClassifier(n_neighbors=bestk)\n",
    "knnClassifier.fit(x_train2, y_train2)\n",
    "y_test_pred2 = knnClassifier.predict(x_test2)\n",
    "matrix = confusion_matrix(y_test2, y_test_pred2)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=matrix)\n",
    "disp.plot()\n",
    "f1_score(y_test2, y_test_pred2, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def9cb0",
   "metadata": {},
   "source": [
    "Overall, KNN had some decent predicting power. As expected, as more features became considered, KNN's prediction accuracy on testing sets declined significantly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c1398e",
   "metadata": {},
   "source": [
    "## MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df343f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before creating the models and such, we msut create the training, validation, and testing splits.\n",
    "#x_temp, x_test, y_temp, y_test = train_test_split(short_df, y_labels, test_size=0.2,stratify=y_labels)\n",
    "#x_train, x_val, y_train, y_val = train_test_split(x_temp, y_temp, test_size=0.2,stratify=y_temp)\n",
    "x_train, x_test, y_train, y_test = train_test_split(short_df, y_labels, test_size=0.2,stratify=y_labels)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "#Because the labels are 1-indexed (starts at 1), we must subtract everything by 1 to make it 0-indexed\n",
    "y_train = y_train-1\n",
    "#y_val = y_val-1\n",
    "y_test = y_test-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6091844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With KNN out of the way, we shall use the keras library to build NN models. Hopefully, the NN models will have a higher\n",
    "#prediction accuracy...\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1886eb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll start with a simple one\n",
    "model = keras.Sequential(name=\"FetusHealthNNmodel1\")\n",
    "model.add(layers.Dense(25, activation='relu',input_dim=7))\n",
    "model.add(layers.Dense(12, activation='relu'))\n",
    "model.add(layers.Dense(3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7cd588c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"FetusHealthNNmodel1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 25)                200       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 12)                312       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 3)                 39        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 551 (2.15 KB)\n",
      "Trainable params: 551 (2.15 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f54b835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "43/43 [==============================] - 2s 15ms/step - loss: 2.4707 - accuracy: 0.7257 - val_loss: 0.6725 - val_accuracy: 0.8059\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.7130 - accuracy: 0.7713 - val_loss: 0.6494 - val_accuracy: 0.8059\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.7094 - accuracy: 0.7713 - val_loss: 0.6515 - val_accuracy: 0.8059\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.7074 - accuracy: 0.7713 - val_loss: 0.6763 - val_accuracy: 0.8059\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.7094 - accuracy: 0.7713 - val_loss: 0.6359 - val_accuracy: 0.8059\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6990 - accuracy: 0.7757 - val_loss: 0.6717 - val_accuracy: 0.7882\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.6970 - accuracy: 0.7757 - val_loss: 0.6758 - val_accuracy: 0.7882\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.6994 - accuracy: 0.7757 - val_loss: 0.6729 - val_accuracy: 0.7882\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.6972 - accuracy: 0.7757 - val_loss: 0.6830 - val_accuracy: 0.7882\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.6977 - accuracy: 0.7757 - val_loss: 0.6722 - val_accuracy: 0.7882\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6973 - accuracy: 0.7772 - val_loss: 0.6883 - val_accuracy: 0.7824\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.6957 - accuracy: 0.7772 - val_loss: 0.6832 - val_accuracy: 0.7824\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.6947 - accuracy: 0.7772 - val_loss: 0.6784 - val_accuracy: 0.7824\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.6925 - accuracy: 0.7772 - val_loss: 0.6919 - val_accuracy: 0.7824\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.6992 - accuracy: 0.7772 - val_loss: 0.7200 - val_accuracy: 0.7824\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6772 - accuracy: 0.7875 - val_loss: 0.7964 - val_accuracy: 0.7412\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.6715 - accuracy: 0.7875 - val_loss: 0.7865 - val_accuracy: 0.7412\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.6748 - accuracy: 0.7875 - val_loss: 0.7575 - val_accuracy: 0.7412\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.6728 - accuracy: 0.7875 - val_loss: 0.7714 - val_accuracy: 0.7412\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.6766 - accuracy: 0.7875 - val_loss: 0.7595 - val_accuracy: 0.7412\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6898 - accuracy: 0.7794 - val_loss: 0.7371 - val_accuracy: 0.7735\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.7794 - val_loss: 0.6914 - val_accuracy: 0.7735\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.6912 - accuracy: 0.7794 - val_loss: 0.7106 - val_accuracy: 0.7735\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.6899 - accuracy: 0.7794 - val_loss: 0.7055 - val_accuracy: 0.7735\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.6891 - accuracy: 0.7794 - val_loss: 0.6923 - val_accuracy: 0.7735\n",
      "14/14 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "nFolds = 5\n",
    "testingCrossValidationError = []\n",
    "for iFold in range(nFolds):\n",
    "    Xti, Xvi, Yti, Yvi = tools.crossValidate(x_train, y_train,nFolds, iFold)\n",
    "    model.fit(Xti, Yti, epochs=5, validation_data=(Xvi, Yvi))\n",
    "    y_test_pred = np.argmax(model.predict(x_test),axis=1) #to get the prediction based off of the softmax results\n",
    "    test_accuracy = accuracy_score(y_test,y_test_pred)\n",
    "    testingCrossValidationError.append(test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a6a3497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.7793427230046949\n",
      "F1 Score: 0.6826960000990994\n"
     ]
    }
   ],
   "source": [
    "avgTestAccuracy = sum(testingCrossValidationError)/nFolds\n",
    "print(\"Testing Accuracy:\",avgTestAccuracy)\n",
    "print(\"F1 Score:\",f1_score(y_test, y_test_pred,average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d67526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
